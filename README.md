# ğŸ¤– No-Code ML Platform

Eine vollstÃ¤ndige Machine Learning Platform, die es ermÃ¶glicht ohne Programmierkenntnisse ML-Modelle zu trainieren und bereitzustellen.

## âœ¨ Features

### ğŸ”§ **Flexible Algorithmus-Auswahl**
- **Klassifikation**: Random Forest, Logistic Regression, SVM, XGBoost
- **Regression**: Random Forest, Linear Regression, SVR, XGBoost
- Automatische Algorithmus-Empfehlungen basierend auf Datentypen
- KomplexitÃ¤ts-Bewertung fÃ¼r jeden Algorithmus

### ğŸ“Š **Intelligente Datenverarbeitung**
- **CSV-Upload & Analyse**: Automatische Datentyp-Erkennung
- **Erweiterte Preprocessing-Pipeline**: Skalierung, One-Hot-Encoding, Label-Encoding
- **Smart Data Cleaning**: Behandlung fehlender Werte
- **Feature-Engineering**: Automatische Preprocessing je nach Datentyp

### ğŸ¯ **Erweiterte Metriken**
- **Klassifikation**: Accuracy, Precision, Recall, F1-Score, AUC-ROC, Classification Report
- **Regression**: MAE, MSE, RMSE, RÂ², MAPE
- **Feature Importance**: Visualisierung der wichtigsten Features

### ğŸ§  **LLM-basierte Script-Generierung**
- **Intelligente Python-Scripts**: MaÃŸgeschneidert fÃ¼r jedes Projekt
- **Adaptive Preprocessing**: Automatisch angepasst an Datentypen
- **Optimierte Algorithmen**: LLM wÃ¤hlt beste Parameter
- **Zero-Template-Ansatz**: VollstÃ¤ndig generierte Scripts statt starrer Templates

### ğŸš€ **Echte REST-API**
- **Training-API**: Automatisches Model-Training mit echten Python-Scripts
- **Prediction-API**: Echte Vorhersagen mit trainierten Modellen
- **Model-Export**: Download der trainierten .pkl-Modelle
- **Persistente Speicherung**: SQLite-Datenbank fÃ¼r alle Projekte

### ğŸ¨ **Moderne BenutzeroberflÃ¤che**
- Intuitive 3-Schritte Wizard fÃ¼r Projekt-Erstellung
- Echzeit-Datei-Analyse mit Spalten- und Zeilenzahl
- Live-Training-Status mit Polling
- Performance-Visualisierung mit Charts
- Responsive Design

## ğŸ—ï¸ Architektur

```
ML-Platform/
â”œâ”€â”€ backend/          # Node.js + Express + SQLite
â”‚   â”œâ”€â”€ server.js     # Haupt-Server mit REST-API
â”‚   â”œâ”€â”€ models/       # Gespeicherte .pkl-Modelle
â”‚   â”œâ”€â”€ scripts/      # Generierte Python-Scripts
â”‚   â””â”€â”€ uploads/      # Hochgeladene CSV-Dateien
â”œâ”€â”€ frontend/         # React + TypeScript
â”‚   â”œâ”€â”€ components/   # UI-Komponenten
â”‚   â”œâ”€â”€ services/     # API-Services
â”‚   â””â”€â”€ types.ts      # TypeScript-Definitionen
â””â”€â”€ README.md
```

## ğŸš€ Installation & Start

### Voraussetzungen
- Node.js (Version 16+)
- Python 3.x mit ML-Paketen:
  ```bash
  pip install pandas scikit-learn joblib numpy xgboost
  ```

### Backend starten
```bash
cd backend
npm install
npm run dev          # Entwicklungsserver auf Port 3001
```

### Frontend starten  
```bash
cd frontend
npm install
npm run dev          # Entwicklungsserver auf Port 5173
```

## ğŸ“¡ API Endpoints

### ğŸ”„ **Projekt-Management**
```http
GET    /api/projects              # Alle Projekte abrufen
POST   /api/projects              # Neues Projekt erstellen  
GET    /api/projects/:id          # Einzelnes Projekt abrufen
DELETE /api/projects/:id          # Projekt lÃ¶schen
```

### ğŸ“¤ **Datei-Upload**
```http
POST   /api/upload           # CSV-Datei hochladen & analysieren
```

### ğŸ¯ **Model-Operationen**
```http
POST   /api/projects/:id/predict  # Vorhersage mit trainiertem Modell
GET    /api/projects/:id/download # Trainiertes Modell herunterladen
```

## ğŸ”¬ Verwendung

### 1ï¸âƒ£ **Projekt erstellen**
- CSV-Datei hochladen
- Automatische Datenanalyse 
- Algorithmus auswÃ¤hlen
- Zielvarible und Features festlegen

### 2ï¸âƒ£ **Training starten**
- **LLM generiert intelligentes Python-Script** basierend auf Ihren Daten
- **Adaptive Preprocessing-Pipeline** je nach Datentypen
- **Echte scikit-learn/XGBoost AusfÃ¼hrung** mit optimierten Parametern
- **Live-Status-Updates** wÃ¤hrend des Trainings
- **Performance-Metriken** werden automatisch extrahiert

### 3ï¸âƒ£ **Modell nutzen**
- **Predictions**: Ãœber UI oder API-Endpoint
- **Export**: .pkl-Datei fÃ¼r lokale Nutzung
- **Analysis**: Performance-Charts und Feature Importance

## ğŸ¯ API-Beispiele

### Prediction-Request
```bash
curl -X POST 'http://localhost:3001/api/projects/{PROJECT_ID}/predict' \
  -H 'Content-Type: application/json' \
  -d '{
    "features": {
      "age": 35,
      "income": 50000,
      "experience": 10
    }
  }'
```

### Response
```json
{
  "prediction": "1",
  "features": {
    "age": 35,
    "income": 50000,
    "experience": 10
  },
  "model": "RandomForestClassifier",
  "projectName": "Employee Churn Prediction"
}
```

## ğŸ”§ Technologie-Stack

### Backend
- **Node.js** + **Express.js** - REST-API Server
- **SQLite** - Persistente Datenspeicherung  
- **Python Integration** - Echte ML-Pipeline mit scikit-learn
- **Multer** - File-Upload-Handling

### Frontend  
- **React** + **TypeScript** - Moderne UI
- **Vite** - Build-Tool
- **Recharts** - Performance-Visualisierung
- **Tailwind CSS** - Styling

### Machine Learning
- **scikit-learn** - Standard ML-Algorithmen
- **XGBoost** - Gradient Boosting
- **pandas** - Datenmanipulation
- **joblib** - Model-Serialisierung

## ğŸ¨ Screenshots

### Projekt-Wizard
![Wizard](docs/wizard.png)

### Performance-Dashboard  
![Dashboard](docs/performance.png)

### API-Integration
![API](docs/api.png)

## ğŸ¤ Beitragen

1. Fork das Repository
2. Feature-Branch erstellen (`git checkout -b feature/amazing-feature`)
3. Ã„nderungen committen (`git commit -m 'Add amazing feature'`)
4. Branch pushen (`git push origin feature/amazing-feature`)
5. Pull Request erstellen

## ğŸ“„ Lizenz

Dieses Projekt steht unter der MIT-Lizenz. Siehe `LICENSE` Datei fÃ¼r Details.

## ğŸ™ Danksagungen

- **scikit-learn** fÃ¼r die exzellente ML-Bibliothek
- **React** fÃ¼r das moderne Frontend-Framework
- **Express.js** fÃ¼r den robusten Backend-Server

---

**Entwickelt mit â¤ï¸ fÃ¼r No-Code Machine Learning** 