services:
  # ML-Platform Service:
  ml-platform:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: ml-platform-backend
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - PORT=3000
      - UNIFIED_SERVICE_URL=http://192.168.0.206:3002
      - FRONTEND_URL=http://192.168.0.206:8080
      - UPLOADS_DIR=/app/uploads
      - MODELS_DIR=/app/models
      - SCRIPT_DIR=/app/scripts
    volumes:
      # WICHTIG: Anonymer Volume für node_modules ZUERST, damit Windows node_modules nicht gemountet werden
      - /app/node_modules
      - ./uploads:/app/uploads
      - ./models:/app/models
      - ./scripts:/app/scripts
      - ./logs:/app/logs
      - ./backend/projects.db:/app/projects.db
      - ./config:/app/config
      # Backend-Code als Volume mounten - Änderungen werden sofort übernommen ohne Rebuild
      # NACH node_modules Volume, damit node_modules nicht überschrieben wird
      - ./backend:/app
    depends_on:
      - unified-service
    restart: unless-stopped
    networks:
      - ml-platform-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Frontend Service (Nginx)
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: ml-platform-frontend
    ports:
      - "8080:80"
    environment:
      - NODE_ENV=production
    depends_on:
      ml-platform:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - ml-platform-network
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 5s

  # Unified ML Service
  unified-service:
    build:
      context: .
      dockerfile: services/unified-service/Dockerfile
    container_name: ml-platform-unified
    ports:
      - "3002:3002"
    environment:
      - NODE_ENV=production
      - PORT=3002
      - OLLAMA_URL=http://192.168.0.206:11434
      - API_GATEWAY_URL=http://192.168.0.206:3000
      - VENV_DIR=/opt/venv
      - SCRIPT_DIR=/app/scripts
      - UPLOADS_DIR=/app/uploads
      - MODELS_DIR=/app/models
    volumes:
      - ./scripts:/app/scripts
      - ./models:/app/models
      - ./uploads:/app/uploads
      - ./logs:/app/logs
      # Code als Volume mounten - Änderungen werden sofort übernommen ohne Rebuild
      - ./services/unified-service:/app/services/unified-service
      - ./config:/app/config
    restart: unless-stopped
    networks:
      - ml-platform-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3002/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

networks:
  ml-platform-network:
    driver: bridge
