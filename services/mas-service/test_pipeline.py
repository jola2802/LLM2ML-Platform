"""
Test-Skript fÃ¼r die ML-Pipeline
Testet die komplette Pipeline mit einem Beispiel-Datensatz
"""

import asyncio
import os
import sys
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
from io import StringIO

# FÃ¼ge Projekt-Root zum Python-Pfad hinzu
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from core.agents.pipline import run_simple_pipeline

# Import fÃ¼r detailliertes Logging
import logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

# Globale Log-Datei
log_file = None
log_file_path = None

class TeeOutput:
    """Klasse die Ausgaben sowohl in Konsole als auch in Datei schreibt"""
    def __init__(self, *files):
        self.files = files
    
    def write(self, obj):
        for f in self.files:
            f.write(obj)
            f.flush()
    
    def flush(self):
        for f in self.files:
            f.flush()

def init_log_file():
    """Initialisiert die Log-Datei mit Timestamp"""
    global log_file, log_file_path
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    log_file_path = os.path.join(project_root, f"pipeline_test_log_{timestamp}.log")
    
    log_file = open(log_file_path, 'w', encoding='utf-8')
    
    # Schreibe Header in Log-Datei
    log_file.write("=" * 80 + "\n")
    log_file.write(f"ML-PIPELINE TEST LOG\n")
    log_file.write(f"Startzeit: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    log_file.write("=" * 80 + "\n\n")
    log_file.flush()
    
    # Leite stdout und stderr um
    sys.stdout = TeeOutput(sys.stdout, log_file)
    sys.stderr = TeeOutput(sys.stderr, log_file)
    
    return log_file_path

def close_log_file():
    """SchlieÃŸt die Log-Datei und stellt stdout/stderr wieder her"""
    global log_file
    
    if log_file:
        log_file.write("\n" + "=" * 80 + "\n")
        log_file.write(f"Endzeit: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        log_file.write("=" * 80 + "\n")
        log_file.close()
        log_file = None
    
    # Stelle stdout/stderr wieder her (falls nÃ¶tig)
    if isinstance(sys.stdout, TeeOutput):
        sys.stdout = sys.stdout.files[0]
    if isinstance(sys.stderr, TeeOutput):
        sys.stderr = sys.stderr.files[0]

def create_test_dataset(output_path: str = "test_dataset.csv") -> str:
    """
    Erstellt einen Test-Datensatz fÃ¼r Klassifikation
    """

    # Check if output_path exists
    if os.path.exists(output_path):
        print(f"ğŸ“Š Test-Datensatz bereits vorhanden: {output_path}")
        return output_path
    
    print(f"\nğŸ“Š Erstelle Test-Datensatz: {output_path}")
    
    # Erstelle synthetische Daten fÃ¼r Klassifikation
    np.random.seed(42)
    n_samples = 500
    
    # Features
    age = np.random.randint(18, 80, n_samples)
    income = np.random.normal(50000, 15000, n_samples)
    credit_score = np.random.normal(650, 100, n_samples)
    years_employed = np.random.randint(0, 40, n_samples)
    
    # Target Variable (KreditwÃ¼rdigkeit basierend auf Features)
    # Einfache Regel: KreditwÃ¼rdig wenn income > 45000 und credit_score > 600
    creditworthy = ((income > 45000) & (credit_score > 600)).astype(int)
    # FÃ¼ge etwas Rauschen hinzu
    noise = np.random.random(n_samples) < 0.15
    creditworthy = (creditworthy ^ noise).astype(int)
    
    # Erstelle DataFrame
    df = pd.DataFrame({
        'age': age,
        'income': income,
        'credit_score': credit_score,
        'years_employed': years_employed,
        'creditworthy': creditworthy
    })
    
    # Speichere CSV
    full_path = os.path.join(project_root, output_path)
    df.to_csv(full_path, index=False)
    
    print(f"âœ… Test-Datensatz erstellt: {full_path}")
    
    return full_path

def print_section(title: str, char: str = "="):
    """Druckt einen Abschnitts-Titel"""
    print(f"\n{char * 80}")
    print(f"{title}")
    print(f"{char * 80}")

def print_dict(data: dict, indent: int = 0, max_depth: int = 3, current_depth: int = 0):
    """Druckt ein Dictionary formatiert"""
    if current_depth >= max_depth:
        print(" " * indent + "...")
        return
    
    for key, value in data.items():
        if isinstance(value, dict):
            print(" " * indent + f"{key}:")
            print_dict(value, indent + 2, max_depth, current_depth + 1)
        elif isinstance(value, list):
            print(" " * indent + f"{key}: [List mit {len(value)} EintrÃ¤gen]")
            if len(value) > 0 and isinstance(value[0], dict):
                for i, item in enumerate(value[:3]):  # Zeige nur erste 3
                    print(" " * (indent + 2) + f"[{i}]:")
                    print_dict(item, indent + 4, max_depth, current_depth + 1)
                if len(value) > 3:
                    print(" " * (indent + 2) + f"... und {len(value) - 3} weitere")
        elif isinstance(value, str) and len(value) > 200:
            print(" " * indent + f"{key}: {value[:200]}...")
        else:
            print(" " * indent + f"{key}: {value}")

async def test_pipeline():
    """Testet die komplette Pipeline"""
    
    print_section("ğŸš€ ML-PIPELINE TEST", "=")
    print(f"Startzeit: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # 1. Erstelle Test-Datensatz
    print_section("ğŸ“Š SCHRITT 1: Test-Datensatz erstellen", "-")
    test_dataset_path = create_test_dataset("test_dataset.csv")
    
    # 2. Erstelle Projekt-Dictionary
    print_section("ğŸ“ SCHRITT 2: Projekt-Dictionary erstellen", "-")
    project = {
        'id': 'test_project_001',
        'name': 'Test Projekt - KreditwÃ¼rdigkeit',
        'csvFilePath': test_dataset_path,
        'userPreferences': 'Klassifikationsproblem: Vorhersage der KreditwÃ¼rdigkeit',
        'llmRecommendations': {
            'targetVariable': 'creditworthy',
            'modelType': 'Classification',
            'algorithm': 'RandomForestClassifier',
            'features': ['age', 'income', 'credit_score', 'years_employed']
        }
    }
    
    print("Projekt-Konfiguration:")
    print_dict(project)
    
    # 3. FÃ¼hre Pipeline aus
    print_section("ğŸ”„ SCHRITT 3: Pipeline-AusfÃ¼hrung", "-")
    print("Starte Pipeline mit max_iterations=2 (fÃ¼r schnelleren Test)")
    
    
    try:
        # Erstelle eine Kopie fÃ¼r besseres Debugging
        import copy
        project_copy = copy.deepcopy(project)
        
        # PrÃ¼fe ob CSV-Datei existiert
        if not os.path.exists(test_dataset_path):
            raise FileNotFoundError(f"Test-Datensatz nicht gefunden: {test_dataset_path}")
        
        # print(f"ğŸ“ Verwendete CSV-Datei: {test_dataset_path}")
        # print(f"ğŸ“Š DateigrÃ¶ÃŸe: {os.path.getsize(test_dataset_path)} Bytes")
        
        # Starte Pipeline
        print("\n" + "=" * 80)
        print("ğŸš€ STARTE PIPELINE...")
        print("=" * 80 + "\n")
        
        result = await run_simple_pipeline(project_copy, max_iterations=2)
        
        print_section("âœ… PIPELINE ERFOLGREICH ABGESCHLOSSEN", "=")
        
        # Validiere Ergebnis
        if not result:
            print("âš ï¸  WARNUNG: Pipeline hat kein Ergebnis zurÃ¼ckgegeben")
            return None
        
        if not isinstance(result, str):
            print(f"âš ï¸  WARNUNG: Pipeline hat unerwarteten Typ zurÃ¼ckgegeben: {type(result)}")
            print(f"   Ergebnis: {result}")
            return result
        
        print(f"ğŸ“ Anzahl Zeilen: {len(result.split(chr(10)))}")
        print("-" * 80)
        
        return result
        
    except FileNotFoundError as error:
        print_section("âŒ DATEI NICHT GEFUNDEN", "=")
        print(f"Fehler: {error}")
        print("\nğŸ’¡ TIPP: Stelle sicher, dass der Test-Datensatz erstellt wurde.")
        raise
    except Exception as error:
        print_section("âŒ PIPELINE FEHLGESCHLAGEN", "=")
        print(f"Fehlertyp: {type(error).__name__}")
        print(f"Fehlermeldung: {error}")
        import traceback
        print("\n" + "=" * 80)
        print("VOLLSTÃ„NDIGER TRACEBACK:")
        print("=" * 80)
        traceback.print_exc()
        print("\nğŸ’¡ TIPP: PrÃ¼fe die Fehlermeldung oben und stelle sicher, dass:")
        print("   - Alle benÃ¶tigten Module installiert sind")
        print("   - Die LLM-API erreichbar ist")
        print("   - Die CSV-Datei korrekt formatiert ist")
        raise

def test_individual_agents():
    """Testet einzelne Agents (optional)"""
    print_section("ğŸ” OPTIONAL: Einzelne Agents testen", "-")
    print("Diese Funktion kann erweitert werden, um einzelne Agents zu testen")
    print("Aktuell wird die komplette Pipeline getestet")

async def main():
    """Hauptfunktion"""
    start_time = datetime.now()
    
    try:
        # Teste komplette Pipeline
        result = await test_pipeline()
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        print_section("ğŸ“Š TEST ZUSAMMENFASSUNG", "=")
        
        if result and isinstance(result, str) and len(result.strip()) > 0:
            print("âœ… Pipeline-Test erfolgreich abgeschlossen")
            print(f"ğŸ“ Generierter Code: {len(result)} Zeichen")
            print(f"ğŸ“ Anzahl Zeilen: {len(result.split(chr(10)))}")
        else:
            print("âš ï¸  Pipeline abgeschlossen, aber kein Code generiert")
            print(f"   Ergebnis-Typ: {type(result)}")
            print(f"   Ergebnis-LÃ¤nge: {len(result) if result else 0}")
        
        print(f"ğŸ“ Test-Datensatz: test_dataset.csv")
        print(f"ğŸ• Startzeit: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ• Endzeit: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"â±ï¸  Dauer: {duration:.2f} Sekunden ({duration/60:.2f} Minuten)")
        
        # Speichere generierten Code in Datei
        output_file = "test_generated_code.py"
        if result and isinstance(result, str) and len(result.strip()) > 0:
            output_path = os.path.join(project_root, output_file)
            try:
                with open(output_path, 'w', encoding='utf-8') as f:
                    f.write(result)
                print(f"ğŸ’¾ Generierter Code gespeichert in: {output_path}")
            except Exception as save_error:
                print(f"âš ï¸  Fehler beim Speichern des Codes: {save_error}")
        else:
            print("âš ï¸  Kein Code zum Speichern verfÃ¼gbar")
        
        print("\n" + "=" * 80)
        if result and isinstance(result, str) and len(result.strip()) > 0:
            print("ğŸ‰ TEST ERFOLGREICH ABGESCHLOSSEN!")
        else:
            print("âš ï¸  TEST ABGESCHLOSSEN (mit Warnungen)")
        print("=" * 80)
        
        if log_file_path:
            print(f"\nğŸ“ Alle Ausgaben wurden in Log-Datei gespeichert: {log_file_path}")
        
        # SchlieÃŸe Log-Datei
        close_log_file()
        
        return 0
        
    except KeyboardInterrupt:
        print_section("âš ï¸  TEST ABGEBROCHEN", "=")
        print("Der Test wurde vom Benutzer abgebrochen (Ctrl+C)")
        if log_file_path:
            print(f"\nğŸ“ Ausgaben bis zum Abbruch wurden in Log-Datei gespeichert: {log_file_path}")
        close_log_file()
        return 1
    except Exception as error:
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        print_section("âŒ TEST FEHLGESCHLAGEN", "=")
        print(f"Fehlertyp: {type(error).__name__}")
        print(f"Fehlermeldung: {error}")
        print(f"ğŸ• Startzeit: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ• Endzeit: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"â±ï¸  Dauer bis Fehler: {duration:.2f} Sekunden")
        
        import traceback
        print("\n" + "=" * 80)
        print("VOLLSTÃ„NDIGER TRACEBACK:")
        print("=" * 80)
        traceback.print_exc()
        
        print("\nğŸ’¡ DEBUGGING-TIPPS:")
        print("   1. PrÃ¼fe ob alle Python-Module installiert sind")
        print("   2. Stelle sicher, dass die LLM-API (Ollama) lÃ¤uft")
        print("   3. PrÃ¼fe ob die CSV-Datei korrekt formatiert ist")
        print("   4. Schaue in die Logs oben nach spezifischen Fehlermeldungen")
        
        if log_file_path:
            print(f"\nğŸ“ Alle Ausgaben wurden in Log-Datei gespeichert: {log_file_path}")
        
        close_log_file()
        
        return 1

if __name__ == "__main__":
    try:
        # Initialisiere Log-Datei frÃ¼h, um auch Start-Meldungen zu erfassen
        log_path = init_log_file()
        
        print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                    ML-PIPELINE TEST-SKRIPT                               â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
        print(f"ğŸ“ Alle Ausgaben werden in Log-Datei gespeichert: {log_path}\n")
        
        exit_code = asyncio.run(main())
        
        # Stelle sicher, dass Log-Datei geschlossen wird
        close_log_file()
        
        sys.exit(exit_code)
    except KeyboardInterrupt:
        print("\n\nâš ï¸  Test wurde vom Benutzer abgebrochen.")
        if log_file_path:
            print(f"ğŸ“ Ausgaben wurden in Log-Datei gespeichert: {log_file_path}")
        close_log_file()
        sys.exit(1)
    except Exception as error:
        print(f"\n\nâŒ Unerwarteter Fehler beim Starten des Tests: {error}")
        import traceback
        traceback.print_exc()
        if log_file_path:
            print(f"ğŸ“ Fehlerausgaben wurden in Log-Datei gespeichert: {log_file_path}")
        close_log_file()
        sys.exit(1)

